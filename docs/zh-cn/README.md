# Lynexus AI助手 - 完整用户指南

## 1. 正常用法

### 1.1 启动应用程序

#### 从源代码运行：
```bash
# 确保已安装 Python 3.8+
python main.py
```

#### 从可执行文件运行（Windows）：
- 从GitHub下载最新版本
- 解压ZIP文件
- 运行 `Lynexus.exe`

### 1.2 初始设置

首次启动Lynexus时，您会看到初始化对话框：

1. **选择API提供商**：从DeepSeek、OpenAI、Anthropic、Local或Custom中选择
2. **输入API密钥**：输入您的API密钥（也可以从配置文件加载）
3. **配置模型设置**：
   - API基础URL：通常由您的API提供商提供
   - 模型：选择要使用的模型
4. **添加MCP工具（可选）**：点击"选择MCP文件"添加自定义工具
5. **点击"开始使用Lynexus"**开始

### 1.3 基本聊天界面

主界面有三个部分：

**左侧边栏**：
- **新建聊天**：创建新对话
- **对话列表**：在不同聊天会话之间切换
- **操作按钮**：设置、工具、导出等

**主聊天区域**：
- **消息显示**：以现代化气泡设计显示聊天历史
- **输入框**：在此处输入消息
- **发送按钮**：提交消息（快捷键Ctrl+Enter）

**状态栏**：
- 显示连接状态、模型信息和工具数量
- 当AI执行命令时显示执行状态

### 1.4 发送消息

1. 在输入框中输入消息
2. 按Enter键或点击发送按钮
3. AI将处理您的请求并回复
4. 如果AI需要执行命令，您将看到实时状态更新

### 1.5 管理对话

**创建新对话**：
- 点击侧边栏中的"新建聊天"
- 输入对话名称
- 新对话将出现在对话列表中

**切换对话**：
- 点击侧边栏中的任意对话
- 每个聊天都维护自己的历史和AI配置

**导出聊天历史**：
- 点击侧边栏中的"导出聊天"
- 选择格式（TXT、JSON或Markdown）
- 选择保存位置（默认为桌面）

**清空当前对话**：
- 点击侧边栏中的"清空聊天"
- 确认删除当前对话中的所有消息

## 2. 如何设置预设

### 2.1 什么是预设？

预设是完整的AI配置，包括：
- API设置（基础URL、模型）
- 模型参数（温度、最大令牌数等）
- 系统提示
- 命令执行设置
- MCP工具配置

### 2.2 创建第一个预设

#### 方法1：通过设置对话框

1. 点击侧边栏中的"设置"
2. 配置所有所需参数：
   - **API配置**：提供商、API密钥、模型
   - **模型参数**：温度、最大令牌数、Top P等
   - **命令配置**：命令标记和分隔符
   - **系统提示**：给AI的自定义指令
   - **MCP工具**：添加自定义工具文件
3. 点击"保存设置"应用到当前对话
4. 点击"保存为配置"导出为预设文件

#### 方法2：通过AI类直接配置

对于高级用户，您可以通过编程方式创建预设：

```python
from aiclass import AI

# 使用自定义配置创建AI实例
my_preset = AI(
    api_key="your_api_key_here",
    api_base="https://api.deepseek.com",
    model="deepseek-chat",
    temperature=0.7,
    max_tokens=4096,
    system_prompt="You are a helpful coding assistant...",
    command_start="EXECUTE:",
    command_separator="|",
    mcp_paths=["./tools/my_tool.py", "./tools/mcp_config.json"]
)
```

### 2.3 将预设保存到文件

1. 在设置对话框中，点击"保存为配置"
2. 选择保存位置和文件名
3. 选择格式（推荐JSON）
4. 预设将被保存，但不包含API密钥以确保安全

**JSON预设结构示例**：
```json
{
    "name": "我的编程助手",
    "version": "1.0.0",
    "api_base": "https://api.deepseek.com",
    "model": "deepseek-chat",
    "temperature": 0.7,
    "max_tokens": 4096,
    "top_p": 1.0,
    "presence_penalty": 0.0,
    "frequency_penalty": 0.0,
    "command_start": "EXECUTE:",
    "command_separator": "|",
    "max_iterations": 15,
    "system_prompt": "你是一个专业的Python程序员...",
    "mcp_paths": [
        "./tools/code_analyzer.py",
        "./tools/file_manager.json"
    ]
}
```

### 2.4 预设创建最佳实践

**编程助手**：
- 较低温度（0.3-0.7）以获得更确定的代码
- 包含文件操作的MCP工具
- 添加包含编码指南的系统提示

**创意写作**：
- 较高温度（0.8-1.2）以获得更多样化的输出
- 包含研究和参考工具
- 包含风格指南的系统提示

**研究助手**：
- 平衡温度（0.5-0.8）
- 包含网络搜索和数据分析工具
- 强调准确性和引用的系统提示

## 3. 如何导入预设

### 3.1 从文件导入

1. 点击侧边栏中的"导入配置"
2. 选择预设文件（.json或.yaml格式）
3. 配置将应用到当前对话
4. MCP工具将自动加载

### 3.2 初始化期间导入

1. 在初始化对话框中，点击"加载配置文件"
2. 选择您的预设文件
3. 所有设置将自动填充
4. 根据需要调整任何设置
5. 点击"开始使用Lynexus"

### 3.3 与他人共享预设

**共享您的预设**：
1. 导出您的配置（设置→保存为配置）
2. 共享JSON/YAML文件
3. **重要**：切勿共享您的`.confignore`文件或包含API密钥的文件

**使用共享的预设**：
1. 从来源下载预设文件
2. 使用上述方法导入
3. 在设置中添加您自己的API密钥

### 3.4 社区预设库

Lynexus支持社区驱动的预设系统。您可以：
1. 在社区论坛上浏览预设
2. 下载符合您需求的预设
3. 导入并立即使用它们
4. 为预设评分和评论以帮助他人

## 4. 常见错误排除

### 4.1 API连接错误

**错误："未提供API密钥"**
- **解决方案**：
  1. 检查设置中是否设置了API密钥
  2. 验证环境变量（DEEPSEEK_API_KEY、OPENAI_API_KEY）
  3. 尝试重新输入API密钥

**错误："连接到API失败"**
- **解决方案**：
  1. 检查互联网连接
  2. 验证API基础URL是否正确
  3. 确保API密钥有足够的额度/权限
  4. 尝试不同的模型或提供商

### 4.2 MCP工具错误

**错误："未找到MCP文件"**
- **解决方案**：
  1. 验证配置文件中的文件路径
  2. 检查指定位置是否存在文件
  3. 使用绝对路径或相对于应用程序目录的相对路径

**错误："函数执行失败"**
- **解决方案**：
  1. 检查工具依赖是否已安装
  2. 验证工具参数是否正确
  3. 检查工具权限（对于文件操作）

### 4.3 命令执行错误

**错误："达到最大执行步骤"**
- **解决方案**：
  1. 在设置中增加max_iterations
  2. 将请求简化为更小的步骤
  3. 对多步操作使用"continue"命令

**错误："命令语法不正确"**
- **解决方案**：
  1. 检查command_start和command_separator设置
  2. 确保AI使用正确的格式
  3. 查看系统提示中的命令指南

### 4.4 UI/应用程序错误

**错误："加载对话历史失败"**
- **解决方案**：
  1. 检查文件权限
  2. 验证配置目录是否存在
  3. 尝试重置配置（先备份）

**错误："应用程序启动时崩溃"**
- **解决方案**：
  1. 检查Python版本（需要3.8+）
  2. 安装所有依赖项：```pip install -r requirements.txt```
  3. 检查是否有冲突的Python安装

## 5. 高级用法

### 5.1 自定义MCP工具开发

**创建Python MCP工具**：
1. 在tools目录中创建Python文件
2. 使用适当的文档字符串定义函数
3. 函数将自动被发现

```python
# 示例：./tools/calculator.py
def add_numbers(a: float, b: float) -> float:
    ```
    将两个数字相加。
    
    参数：
    a: 第一个数字
    b: 第二个数字
    
    返回：
    a和b的和
    ```
    return a + b

def multiply_numbers(a: float, b: float) -> float:
    ```
    将两个数字相乘。
    
    参数：
    a: 第一个数字
    b: 第二个数字
    
    返回：
    a和b的乘积
    ```
    return a * b
```

**创建JSON MCP配置**：
1. 创建定义MCP服务器的JSON文件
2. 遵循MCP规范格式
3. 放在tools目录或任何可访问的位置

### 5.2 自定义系统提示

**高级提示工程**：
- 使用系统提示定义AI行为
- 包含正确命令用法的示例
- 设置约束和指南
- 定义响应格式

```text
高级系统提示示例：

你是Lynexus AI，一个可以执行命令的助手。

命令格式：
{command_start}tool_name{command_separator}param1{command_separator}param2

规则：
1. 当用户请求操作时，仅输出命令行
2. 当用户提问时，直接回答
3. 执行前始终验证参数
4. 如果不确定，请要求澄清

可用工具：
- file_read：读取文件内容
- file_write：写入文件
- web_search：搜索网络

示例：
用户："天气怎么样？"
AI："我需要使用天气工具。请添加天气MCP工具。"

用户："读取config.txt"
AI："{command_start}file_read{command_separator}config.txt"
```

### 5.3 多对话管理

**每个对话独立的AI实例**：
- 每个聊天维护独立的AI配置
- 历史分别保存
- 适用于不同的项目或上下文

**在对话之间共享配置**：
1. 从一个对话导出配置
2. 导入到另一个对话
3. 所有设置将被复制

### 5.4 命令行界面

**从终端运行AI**：
```bash
# 运行控制台界面
python aiclass.py

# 从配置文件创建AI
python -c "
from aiclass import create_ai_from_config
ai = create_ai_from_config('my_config.json')
response = ai.process_user_inp('Hello, world!')
print(response)
"
```

**使用AI进行批量处理**：
```python
from aiclass import AI

# 初始化AI
ai = AI(api_key="your_key", model="deepseek-chat")

# 处理多个输入
inputs = ["第一个请求", "第二个请求", "第三个请求"]
for inp in inputs:
    response, completed = ai.process_user_inp(inp)
    print(f"输入：{inp}")
    print(f"响应：{response}")
    print("-" * 50)
    ai.reset_conversation()  # 清除下一个请求的历史
```

### 5.5 与其他系统集成

**Webhook集成**：
- 将Lynexus用作AI后端
- 在AI类周围创建REST API包装器
- 处理来自Web应用程序的请求

**自动化脚本**：
- 安排定期的AI任务
- 处理文件并生成报告
- 监控系统并在条件满足时发出警报

**开发工作流集成**：
- 代码审查协助
- 自动化测试建议
- 文档生成

## 6. 完整参数参考

### 6.1 API配置参数

#### api_key
**用途**：访问AI API服务的身份验证密钥
**数据范围**：字符串（通常为40-60个字符，以"sk-"开头）
**默认值**：无（如果可用，则从环境变量读取）
**示例与效果**：
- 正确：`"sk-1234567890abcdef1234567890abcdef"`
  - 结果：API身份验证成功
- 空：`""`
  - 结果：错误："未提供API密钥且未在环境变量中找到API密钥"
- 无效：`"invalid_key"`
  - 结果：API返回401未授权错误

#### api_base
**用途**：AI API端点的基本URL
**数据范围**：有效的URL字符串
**默认值**：`"https://api.deepseek.com"`
**示例与效果**：
- DeepSeek：`"https://api.deepseek.com"`
  - 结果：连接到DeepSeek的官方API
- OpenAI：`"https://api.openai.com/v1"`
  - 结果：连接到OpenAI的API
- 本地：`"http://localhost:11434"`
  - 结果：连接到本地Ollama服务器
- 无效：`"not-a-url"`
  - 结果：连接失败，网络错误

#### model
**用途**：指定要使用的AI模型
**数据范围**：字符串，API支持的模型名称
**默认值**：`"deepseek-chat"`
**示例与效果**：
- DeepSeek：`"deepseek-chat"`
  - 结果：使用DeepSeek的标准聊天模型
- DeepSeek V3：`"deepseek-chat"`
  - 结果：使用最新的DeepSeek V3模型
- OpenAI：`"gpt-4-turbo"`
  - 结果：使用GPT-4 Turbo模型
- Anthropic：`"claude-3-opus-20240229"`
  - 结果：使用Claude 3 Opus模型
- 无效：`"nonexistent-model"`
  - 结果：API返回未找到模型错误

### 6.2 模型行为参数

#### temperature
**用途**：控制响应的随机性/创造性
**数据范围**：0.0到2.0（浮点数）
**默认值**：1.0
**示例与效果**：
- 0.0：完全确定性
  - 结果：对于相同的输入总是给出相同的响应
  - 用例：代码生成、事实性答案
- 0.5：平衡
  - 结果：一致但有一些变化
  - 用例：技术写作、分析
- 1.0：默认创造性
  - 结果：自然、多样的响应
  - 用例：一般对话
- 1.5：高创造性
  - 结果：更令人惊讶、创造性的输出
  - 用例：创意写作、头脑风暴
- 2.0：最大随机性
  - 结果：高度不可预测的响应
  - 用例：想法生成、探索

#### max_tokens
**用途**：生成响应中的最大令牌数
**数据范围**：1到8192（或API限制，0表示无限制）
**默认值**：2048
**示例与效果**：
- 512：非常短的响应
  - 结果：简洁的答案，可能被截断
  - 用例：快速问题、摘要
- 2048：标准长度
  - 结果：完整的段落、典型对话
  - 用例：大多数一般用途
- 4096：长响应
  - 结果：详细的解释、文章
  - 用例：复杂分析、文档
- 8192：最大实际长度
  - 结果：非常详细、全面的响应
  - 用例：报告生成、长篇内容
- 0或None：无限制
  - 结果：使用API的最大限制
  - 用例：无论长度如何都需要完整答案的情况

#### top_p
**用途**：核采样 - 通过概率质量控制多样性
**数据范围**：0.0到1.0（浮点数）
**默认值**：1.0
**示例与效果**：
- 0.1：非常专注
  - 结果：仅考虑最可能的令牌
  - 用例：事实性、精确的答案
- 0.5：平衡采样
  - 结果：考虑可能的令牌，排除不可能的令牌
  - 用例：一般对话
- 0.9：广泛采样
  - 结果：包括更多样化的令牌选择
  - 用例：创造性任务
- 1.0：无过滤（默认）
  - 结果：考虑所有令牌
  - 用例：当您想要最大多样性时

#### presence_penalty
**用途**：根据令牌是否已出现在文本中对其进行惩罚
**数据范围**：-2.0到2.0（浮点数）
**默认值**：0.0
**示例与效果**：
- -2.0：强烈的重复鼓励
  - 结果：更可能重复单词和短语
  - 用例：诗歌、有节奏的写作
- -1.0：轻微的重复鼓励
  - 结果：稍微更重复
  - 用例：具有一致术语的技术文档
- 0.0：无惩罚（默认）
  - 结果：中性行为
  - 用例：一般用途
- 1.0：轻微的重复避免
  - 结果：尝试避免重复单词
  - 用例：创意写作、避免冗余
- 2.0：强烈的重复避免
  - 结果：积极避免任何重复
  - 用例：当多样性至关重要时

#### frequency_penalty
**用途**：根据令牌在文本中的频率对其进行惩罚
**数据范围**：-2.0到2.0（浮点数）
**默认值**：0.0
**示例与效果**：
- -2.0：强烈的频率鼓励
  - 结果：常见单词变得更加常见
  - 用例：为初学者简化语言
- -1.0：轻微的频率鼓励
  - 结果：稍微偏爱常见单词
  - 用例：清晰、简单的解释
- 0.0：无惩罚（默认）
  - 结果：自然的单词频率
  - 用例：一般对话
- 1.0：轻微的频率避免
  - 结果：尝试使用较少见的单词
  - 用例：复杂的写作、学术论文
- 2.0：强烈的频率避免
  - 结果：积极避免常见单词
  - 用例：诗歌或高度风格化的写作

### 6.3 命令执行参数

#### command_start
**用途**：指示AI要执行命令的标记
**数据范围**：任何字符串（建议避免常见单词）
**默认值**：`"YLDEXECUTE:"`
**示例与效果**：
- `"YLDEXECUTE:"`
  - 结果：AI输出"YLDEXECUTE:tool_name￥|param1￥|param2"
  - 优势：独特，不太可能出现在正常文本中
- `"EXEC:"`
  - 结果：AI输出"EXEC:tool_name|param1|param2"
  - 优势：更短，更易读
- `"RUN:"`
  - 结果：AI输出"RUN:tool_name|param1|param2"
  - 优势：直观，易于理解
- `"CMD:"`
  - 结果：AI输出"CMD:tool_name|param1|param2"
  - 优势：含义清晰
- 有问题：`"Please:"`
  - 结果：当AI说"Please: explain this"时出现误报
  - 劣势：在正常对话中太常见

#### command_separator
**用途**：分隔命令名称与参数以及参数之间
**数据范围**：任何字符串（建议使用非ASCII或唯一字符）
**默认值**：`"￥|"`（日元符号+管道符号）
**示例与效果**：
- `"￥|"`（默认）
  - 结果：`YLDEXECUTE:tool_name￥|param1￥|param2`
  - 优势：独特组合，不太可能出现在正常文本中
- `"|"`
  - 结果：`EXEC:tool_name|param1|param2`
  - 优势：标准管道分隔符，外观整洁
- `"::"`
  - 结果：`EXEC:tool_name::param1::param2`
  - 优势：双冒号，视觉上明显
- `"||"`
  - 结果：`EXEC:tool_name||param1||param2`
  - 优势：双管道，非常明显
- 有问题：`","`
  - 结果：包含逗号的参数出现问题
  - 劣势：数据中常见，导致解析错误

#### max_iterations
**用途**：停止前最大命令执行循环次数
**数据范围**：1到100（整数）
**默认值**：15
**示例与效果**：
- 5：非常短的执行链
  - 结果：5次命令执行后停止
  - 用例：简单、快速的任务
- 15：标准（默认）
  - 结果：允许中等复杂度的多步任务
  - 用例：大多数常见用例
- 30：扩展执行
  - 结果：允许复杂的多步工作流
  - 用例：复杂自动化、研究任务
- 50：最大实际值
  - 结果：可能执行很长的执行链
  - 用例：具有许多步骤的复杂分析
- 100：极端
  - 结果：可能陷入循环
  - 警告：谨慎使用，监控执行

### 6.4 工具配置参数

#### mcp_paths
**用途**：MCP工具文件路径列表（.py、.json、.yaml）
**数据范围**：文件路径字符串数组
**默认值**：`[]`（空列表）
**示例与效果**：
- 空：`[]`
  - 结果：没有可用工具，AI只能对话
  - 用例：纯聊天模式
- Python工具：`["./tools/calculator.py", "./tools/file_ops.py"]`
  - 结果：这些文件中的函数变为可用工具
  - 用例：自定义Python函数作为工具
- JSON配置：`["./tools/mcp_config.json"]`
  - 结果：JSON中定义的MCP服务器和工具变为可用
  - 用例：外部MCP服务器连接
- 混合：`["./tools/local.py", "./tools/external.json"]`
  - 结果：既有本地Python函数，又有外部MCP工具
  - 用例：全面的工具集
- 无效路径：`["./nonexistent.py"]`
  - 结果：警告消息，工具未加载
  - 解决方案：检查文件存在性和权限

#### system_prompt
**用途**：定义AI行为和能力的指令
**数据范围**：字符串（通常100-10,000个字符）
**默认值**：根据配置自动生成
**示例与效果**：
**最小提示**（100字符）：
```text
你是一个有用的助手。清晰简洁地回答问题。
```
结果：基本的帮助行为，没有特殊能力

**标准编程助手**（500字符）：
```text
你是一个专业的Python程序员。帮助用户编写干净、高效的代码。
清晰地解释概念。当要求编写代码时，提供完整、可工作的示例并附上注释。
专注于最佳实践和PEP 8指南。
```
结果：AI专攻Python，提供详细的代码示例

**创意写作者**（800字符）：
```text
你是一个专门从事小说和诗歌创作的创意写作助手。
帮助用户发展角色、情节和背景。提供生动的描述和富有想象力的想法。
使用丰富的词汇和多样的句子结构。在保持连贯性的同时鼓励创造力。
```
结果：AI专注于创意写作，使用表达性语言

**严格的命令执行者**（1200字符）：
```text
你是Lynexus AI。你可以使用以下格式执行命令：
YLDEXECUTE:tool_name￥|param1￥|param2

规则：
1. 仅当用户明确请求操作时才输出YLDEXECUTE:命令
2. 对于问题，直接回答而不使用命令
3. 在命令前后永远不要解释你的操作
4. 仅使用可用工具：file_read、file_write、web_search

示例：
用户："读取配置文件"
你："YLDEXECUTE:file_read￥|config.txt"
```
结果：AI严格遵守命令协议，没有多余文本

**复杂的多角色**（2000+字符）：
```text
你是具有多种能力的Lynexus AI。你的行为取决于上下文：

1. 当用户提出技术问题时：作为具有深入知识的专家
2. 当用户请求文件操作时：高效使用适当的工具
3. 当用户需要创意帮助时：富有想象力且支持性
4. 当用户给出模糊请求时：要求澄清问题

可用工具：[工具列表及描述]

命令格式：[详细的命令语法]

错误处理：[具体的错误响应指南]
```
结果：上下文感知行为，处理多样化的请求

### 6.5 高级参数

#### stream
**用途**：是否逐个令牌流式传输响应
**数据范围**：布尔值（True/False）
**默认值**：False
**示例与效果**：
- False：一次完整响应
  - 结果：等待完整响应，然后显示
  - 优势：整洁、完整的响应
  - 用例：大多数情况，更适合命令解析
- True：到达时流式传输令牌
  - 结果：逐个字符地显示响应构建过程
  - 优势：感觉更响应
  - 用例：等待时间明显的长响应

#### stop
**用途**：AI应停止生成的序列
**数据范围**：字符串数组或None
**默认值**：None
**示例与效果**：
- None：没有特殊的停止序列
  - 结果：AI生成直到max_tokens或自然停止
- `["\n\n", "###", "END"]`：多个停止序列
  - 结果：在双换行符、"###"或"END"处停止
  - 用例：结构化输出、部分
- `["User:", "Assistant:"]`：对话标记
  - 结果：在开始新轮次前停止
  - 用例：多轮模拟
- `["</response>"]`：XML/HTML标签
  - 结果：在闭合标签处停止
  - 用例：结构化数据生成

### 6.6 参数组合示例

#### 示例1：精确技术助手
```python
AI(
    temperature=0.3,
    max_tokens=1024,
    top_p=0.9,
    presence_penalty=0.5,
    frequency_penalty=0.3,
    system_prompt="你是一个精确的技术助手..."
)
```
**结果**：简洁、专注、避免重复，适合文档

#### 示例2：创意头脑风暴伙伴
```python
AI(
    temperature=1.2,
    max_tokens=4096,
    top_p=0.95,
    presence_penalty=-0.5,
    frequency_penalty=-0.3,
    system_prompt="你是一个创意头脑风暴伙伴..."
)
```
**结果**：广泛、富有想象力，强调重复以突出重点

#### 示例3：严格的命令执行者
```python
AI(
    temperature=0.1,
    max_tokens=512,
    command_start="CMD:",
    command_separator="||",
    max_iterations=10,
    system_prompt="仅在需要操作时输出CMD:命令..."
)
```
**结果**：高度可预测，输出最少，非常适合自动化

#### 示例4：平衡的一般助手
```python
AI(
    temperature=0.7,
    max_tokens=2048,
    top_p=1.0,
    presence_penalty=0.0,
    frequency_penalty=0.0,
    system_prompt="你是一个有帮助、平衡的助手..."
)
```
**结果**：自然、多用途，适合日常任务

### 6.7 参数调整指南

**当响应太重复时**：
- 增加`presence_penalty`（0.5到1.5）
- 增加`frequency_penalty`（0.5到1.5）
- 略微降低`temperature`

**当响应太随机时**：
- 降低`temperature`（0.3到0.7）
- 降低`top_p`（0.7到0.9）
- 略微增加`presence_penalty`

**当响应太短时**：
- 增加`max_tokens`（2048到4096）
- 检查`stop`序列是否提前触发

**当命令执行失败时**：
- 验证`command_start`和`command_separator`是否与系统提示匹配
- 确保工具在`mcp_paths`中正确加载
- 检查AI是否被`max_tokens`截断

**当AI忽略系统提示时**：
- 使提示更明确和详细
- 包括所需行为的清晰示例
- 考虑降低`temperature`以获得更多遵守

### 6.8 参数优化工作流

1. **从默认值开始**：首先使用所有默认参数
2. **识别问题**：注意响应中的问题
3. **调整一个参数**：一次只更改一个参数
4. **系统测试**：每次使用相同的测试提示
5. **记录更改**：记录每个更改的作用
6. **迭代**：重复直到达到所需行为
7. **保存预设**：导出您的优化配置

**优化过程示例**：
```
初始：temperature=1.0 → 响应太随机
测试1：temperature=0.7 → 更好但仍然有些随机
测试2：temperature=0.5 → 良好的平衡，保留了创造性
测试3：添加top_p=0.9 → 进一步聚焦响应
测试4：添加presence_penalty=0.3 → 减少重复
最终：temperature=0.5，top_p=0.9，presence_penalty=0.3
```

这个完整的参数参考应该帮助您理解和优化Lynexus AI助手的每个方面。请记住，最佳设置取决于您的具体用例，因此请进行实验，找到最适合您需求的方法。